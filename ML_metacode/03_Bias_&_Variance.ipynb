{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data vs Test Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터의 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 입력된 데이터는 학습 데이터와 평가 데이터로 나눌 수 있다.\n",
    "- 학습 데이터는 모델 학습에 사용되는 모든 데이터셋\n",
    "- 평가 데이터는 오직 모델의 평가만을 위해 사용되는 데이터셋\n",
    "- 평가 데이터는 `절대로 모델 학습에 사용해서는 안된다`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평가 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습 데이터와 평가 데이터는 같은 분포를 가지는가?\n",
    "- 평가 데이터는 어느 정도 크기를 가지는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> 이는 어떤 업무를 하느냐에 따라 다른 분포를 가지게 된다. <br>\n",
    "맨 처음에는 하나의 전체 데이터를 제공한다. ( 학습 데이터와 테스트 데이터를 따로 제공하지 않는다. ) <br>\n",
    "데이터가 들어왔을 때 , 테스트 데이터를 전체 데이터의 10~20% 정도로 사용하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 나눌 때 전체 데이터를 처음부터 80%번째까지 순서대로 잘라서 사용하는 것이 아니라, <br>\n",
    "랜덤하게 80%의 데이터를 가져서 추출해내어 학습 데이터로 사용한다. <br>\n",
    "인접한 데이터 간에 편향성이 존재할 수도 있기 때문이다. <br>\n",
    "따라서 랜덤으로 추출하면, 테스트 데이터와 훈련 데이터의 분포가 매우 비슷하게 유지할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias - Variance : Trade-Off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델의 복잡도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 선형에서 비선형 모델로 갈 수록, 복잡도가 증가한다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가령 `axi + b` 의 식에서 파라미터는 a, b 2개이다. <br>\n",
    "그러나 `axi^2 + bxi + c` 의 식에서 파라미터는 a, b, c 3개이다. <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델이 복잡해질 수록, 학습 데이터를 더 완벽하게 학습한다.\n",
    "항이 많아질 수록 파라미터의 개수도 많아지고, 복잡해진다. 그러나 더 정확한 예측이 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전 경사하강법에서 epoch에 대한 횟수를 무한대로 늘릴 수록, 비선형 모델에서 <br>\n",
    "간단한 선형 모델에 비해 더 정교한 예측이 가능하다. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그러나 평가 데이터의 분포가 훈련 데이터의 분포가 매우 다를 시에 비선형 모델의 문제점이 많아진다. <br>\n",
    "- 그러면 좋은가 ? \n",
    "    1. 데이터가 많은 상황( Under-Fitting )\n",
    "    2. 데이터가 적은 상황( Over-fitting , 과적합 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터가 많은 상황 - Under-Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 복잡도가 높아질 수록, 경사하강법을 더 많이 사용할 수록( epoch의 수가 늘어날 수록 ) 학습 데이터에 대한 정확도가 높아진다. <br> \n",
    "모델의 복잡도가 낮을 수록 , 학습 데이터에 대한 정확도가 매우 낮다. ( Under-Fitting ) <br>\n",
    "다양한 결과의 데이터가 많을 수록, 복잡도가 낮은 선형 데이터는 점점 발생하는 예외를 수용할 수 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 과적합 - Over-Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가령 전체 데이터 셋의 규모가 작은데, 학습 데이터와 테스트 데이터의 분포가 많이 다를 수도 있다. ( 학습 데이터가 매우 적기 때문에 ) <br>\n",
    "선형 모델에서는 학습 데이터와 테스트 데이터 중간 어디에선가 매우 애매하게 선이 그일 것이다. <br>\n",
    "그러나 비선형 모델은 학습 데이터를 매우 확실하게 반영하기 위해 테스트 데이터에 거의 겹치지 않는 모델을 제시할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 상황에서는, 오히려 <br>\n",
    "비선형 모델이 선형 모델보다 더 큰 오차를 발생하게 된다. <br>\n",
    "이를 `과적합`이라 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  요약\n",
    "- 따라서 학습 데이터를 완벽하게 반영하기 위해 무작정 복잡도를 늘리는 행위는 상황에 따라 바람직하지 않을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 편향(Bias)과 분산(Variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 편향과 분산은 모든 알고리즘이 가지고 있는 에러의 종류이다. <br>\n",
    "MSE = 오차의 제곱의 평균 <br>\n",
    "MSE를 통해 편향과 분산을 수식적으로 구할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가령 θ라는 정답지가 있다고 하자. <br>\n",
    "그리고 θ를 예측하기 위해 θ^라는 모델을 통해 예측을 해보았더니 <br>\n",
    "θ 근처에 많이 분포하도록 학습을 해보았지만 , 틀린 부분도 있다는 가정을 해 보았다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이때 `MSE(오차의 제곱의 평균)을 구해보자`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE(θ^) = E( (θ^-θ)^2 ) = E( (θ^ - E(θ^) + E(θ^) - θ)^2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> 앞항(θ^ - E(θ^) 의 제곱 + 뒷항(E(θ^) - θ)의 제곱 + 2 * 앞항 * 뒷항"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이때 전체 수식 틀에 E(평균)을 붙인다. 이때 `θ는 정확한 값이기 때문에 랜덤성이 없어서 E(θ) = θ`이다. <br>\n",
    "또한 평균의 평균은 그냥 한번 평균을 구한 것과 같다. `E(E(θ^)) = E(θ^)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서 앞항 제곱의 평균과 뒷항의 제곱만 남게 된다. 중간항은 사라진다. ( 강의에 풀이 있다. )<br>\n",
    "E( (θ^ - E(θ^))^2 ) + (E(θ^) - θ)^2 = <br>\n",
    "Varθ(θ^) + Biasθ(θ^, θ)^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 더 직관적으로 이해해 보자. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bias : θ에 접근하기 위한 수많은 예측값들의 평균과 실제 θ값의 차이\n",
    "    - 학습 데이터에 대한 정확도\n",
    "- Var(Variance) : 각 수많은 예측값들과 그 값들의 평균의 차이를 제곱한 것의 평균\n",
    "    - E( (θ^-E(θ^))^2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 분산이 적다 : 여러 번 예측을 하더라도, 비슷비슷한 분포를 가진다. \n",
    "- 분산이 크다 : 여러 번 예측을 할 때마다, 예측값에 대한 분포가 매번 크게 다르다.\n",
    "- 이는 사실 편향과는 관련이 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분산과 편향도를 그림으로 그려볼 수 있다. ( 강의 2:37:07 ) <br>\n",
    "빨간색 핵은 실제 θ의 값 , 과녁 형태로 , 표본이 θ값에서 멀어질 수록 중앙에서 멀어진다. <br>\n",
    "실제로 각 표본은 뭉쳐있을 수 있으나, 그 값들이 실제 값과는 다를 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "편향은 `under-fitting`과 관련 있는 개념 <br>\n",
    "분산은 `over-fitting`과 관련 있는 개념 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가령 1번, 2번, 3번 데이터셋이 서로 다른 양상을 보이는데, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trade-Off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "강의 2:39:34에 그래프 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "편향이라는 개념을 보면 , 복잡도가 높아질 수록 편향에 대한 에러율이 낮아진다. <br>\n",
    "분산이라는 개념을 보면 , 복잡도가 높아질 수록 분산에 대한 에러율이 높아진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "편향과 분산을 더한 MSE_loss가 최저값이 되는 실제 optimal한 복잡도가 선형 <-> 비선형 사이 어딘가에 있고, <br>\n",
    "이때의 최저값을 갖는 부분이 가장 적절한 복잡도이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 어떻게 trade-off를 처리할 수 있을까 ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 검증 데이터셋을 활용\n",
    "2. K-fold Cross Validation\n",
    "3. 정규화 손실 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 검증 데이터셋( Valididation Data )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 학습의 정도를 검증하기 위한 데이터셋\n",
    "- 모델 학습에 직접적으로 참여하지 못함\n",
    "- 학습 중간에 계속해서 평가를 하고, 가장 좋은 성능의 파라미터를 저장해 둔다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전에는 전체 데이터 중 무작위 80%를 학습 데이터셋으로 사용했고, 20%의 데이터셋을 테스트 데이터셋으로 사용했다. <br>\n",
    "하지만 이번에는 무작위 805를 학습 데이터셋 , 10%를 확인 데이터셋 , 10%를 테스트 데이터셋으로 사용해보자. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valid 데이터셋과 test 데이터셋의 차이 : <br>\n",
    "valid 데이터셋 : 학습 시에 볼 수 있다. `<->` test 데이터셋 : 학습 시에 볼 수 없다. <br>\\\n",
    "물론 둘 다 모델의 학습에는 참여할 수 없다. <br>\n",
    "검증 데이터셋은 학습 중간에 계속해서 평가를 하기 위해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 중간에 계속해서 평가를 해서, 가장 좋은 파라미터를 저장해 둔다. <br>\n",
    "-> over-fitting을 막는 효과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Leave-One-Out Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증 데이터셋을 나눠줄 때 , 얼마나 나눠줄 지에 대한 하이퍼 파라미터를 제거하기 위해 <br>\n",
    "맨 처음에 LOOCV라는 방법론을 설정해 준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 맨 처음에 랜덤으로 생성된 검증 데이터셋 하나는 편향된 결과를 줄 수도 있다.\n",
    "    - 맨 처음 생성된 검증 데이터셋으로 인해 설정된 최적이라고 믿었던 파라미터로 테스트 세트를 돌렸더니\n",
    "    - 결과가 잘 나올 수도 있고, 잘 안 나올 수도 있다.\n",
    "    - `검증 데이터를 한 번만 사용하는 것이 맞느냐?` 의 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가령 학습 데이터 셋의 데이터 갯수를 n개라고 하자. <br>\n",
    "그렇다면 하나의 데이터 셋을 검증 테스트로 하여, n번 실행한다. <br>\n",
    "-> 간단하게 모든 학습 데이터셋으로 검증을 진행할 수 있다. 그런데 비용이 많이 발생한다. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### k-fold 교차 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LOOCV의 경우 계산 비용이 매우 큰 단점이 있다.\n",
    "- 이러한 문제를 해결하기 위해 , K개의 파트로 나누어 검증을 진해하는 방법론\n",
    "    - 전체 학습 세트가 n개라면 , 교차 검증 1번에 필요한 valid data셋은 n/k개\n",
    "- 예 ) 4-fold 교차 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가령 선형 모델이 1차 ~ 5차 함수 5개가 있다고 하자. <br>\n",
    "이를 모두 Valid 데이터셋으로 검증하려면 , LOOCV로서는 n * 5번 해야 한다. ( 매우 큰 비용 발생 ) <br>\n",
    "그러나 k-fold 교차 검증으로는 , 5 * k번 만 하면 된다. ( LOOCV에 비해 매우 적은 비용 발생 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그러면 , k값이 커지면 어떤 것이 바뀔까 ? -> LOOCV와 비슷해진다.\n",
    "- 학습 데이터의 수가 커진다. <br>\n",
    "하나의 valid를 위한 n/k가 작아지므로 , 나머지 학습을 위한 세트의 갯수는 많아진다.\n",
    "- Bias 에러 값은 작아지고, Variance의 에러 값이 커진다. <br>\n",
    "매 case의 검증에 대해 편차가 커질 것이므로 variation이 커진다. <br>\n",
    "거의 매 case에 비슷한 횟수, 범주에 걸쳐 검증하므로 bias값은 작아진다.\n",
    "- 계산 비용이 커진다. ( LOOCV와 비슷해지므로 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 정규화( Regularization ) - 손실 함수를 건드린다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델의 복잡도나 커진다 = 모델의 파라미터 수가 많아진다\n",
    "- 모델의 복잡도가 커질 수록 -> 과적합( over-fitting )이 발생할 가능성이 커진다.\n",
    "- 복잡도가 큰 모델을 정의하고, 그 중 `중요한 파라미터만 학습`하면 안될까 ?\n",
    "- `필요없는 파라미터의 값을 0으로` 만들자 ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일단 2만 개 정도의 큰 복잡도를 가진 함수를 설정하고 , <br>\n",
    "복잡도를 계산한 다음 , 주요한 파라미터만 남겨두고, 나머지는 모두 삭제한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규화 종류\n",
    "- Ridge 회귀( L2 Regression )\n",
    "- Lasso 회귀( L1 Regression )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ridge 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L = sum( yi - )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('vscode')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2bfdf95f64224930efe8c4672c86eeee98528d89004da92f06cad876fd4ab1dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
